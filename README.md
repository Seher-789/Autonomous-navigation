# Autonomous Navigation with LiDAR-Camera Fusion and TD3

This project demonstrates autonomous navigation using **LiDAR-Camera fusion** and the **TD3** deep reinforcement learning algorithm in a ROS and Gazebo-based simulation environment.

The system uses LiDAR-Camera fusion to perceive the environment and navigates autonomously using the **TD3** (Twin Delayed Deep Deterministic Policy Gradient) algorithm. Training takes place in a simulated environment built on **ROS Noetic** and **Gazebo 11**.

---

## Requirements

- **ROS Noetic**  
- **Gazebo 11**  
- **Ubuntu 20.04**

---

## Installation, Setup, and Training

### Step 1: Clone the repository

```bash
git clone https://github.com/Seher-789/Autonomous-navigation.git
cd ~/Autonomous-navigation/DRL-robot-navigation/catkin_ws


Reference Paper
Seher and R. A. Wagan,
"Twin Delayed Deep Deterministic Policy Gradient for Adaptive Autonomous Navigation with LiDAR and Camera Sensor Fusion in Diverse Environment,"
2025 International Conference on Communication Technologies (ComTech), Rawalpindi, Pakistan, 2025, pp. 1-6,
doi: 10.1109/ComTech65062.2025.11034457.

